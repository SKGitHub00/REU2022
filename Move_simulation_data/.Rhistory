#----------------Nine----------------
test_data_9 = function(){
first = rnorm(45, mean = 10, sd = 1)
second = rnorm(45, mean = 10, sd = 5)
data_9 = c(first, second)
test_data_9 = data.frame(time, data_9)
return(test_data_9)
}
#----------------Ten----------------
test_data_10_fun = function(){
first = rnorm(30, mean = 10, sd = 1)
second = rnorm(30, mean = 10, sd = 5)
third = rnorm(30, mean = 10, sd = 1)
data_10 = c(first, second, third)
test_data_10 = data.frame(time, data_10)
return(test_data_10)
}
#----------------plots----------------
#par(mfrow=c(3,4))
#plot(test_data_0_a, main = "0 Breaks, Low Variance", xlab="Time", ylab="Dependent Variable")
#plot(test_data_0_b, main = "0 Breaks, High Variance", xlab="Time", ylab="Dependent Variable")
#plot(test_data_1, main = "1 Break, Low Variance", xlab="Time", ylab="Dependent Variable")
#plot(test_data_2, main = "2 Breaks, Low Variance", xlab="Time", ylab="Dependent Variable")
#plot(test_data_3, main = "1 Break, High Variance", xlab="Time", ylab="Dependent Variable")
#plot(test_data_4, main = "2 Breaks, High Variance", xlab="Time", ylab="Dependent Variable")
#plot(test_data_5, main = "1 Break, Big Slopes", xlab="Time", ylab="Dependent Variable")
#plot(test_data_6, main = "2 Breaks, Big Slopes", xlab="Time", ylab="Dependent Variable")
#plot(test_data_7, main = "1 Break, Small Slopes", xlab="Time", ylab="Dependent Variable")
#plot(test_data_8, main = "2 Breaks, Small Slopes", xlab="Time", ylab="Dependent Variable")
#plot(test_data_9, main = "1 Breaks, Variance Change", xlab="Time", ylab="Dependent Variable")
#plot(test_data_10, main = "2 Breaks, Variance Change", xlab="Time", ylab="Dependent Variable")
#par(mfrow=c(1,1))
data_fun = test_data_1 #edit here !!! (defines function for generating draws)
first = rnorm(30, mean = 5, sd = 1)
second = rnorm(30, mean = 15, sd = 1)
third = rnorm(30, mean = 30, sd = 1)
data_2 = c(first, second, third)
test_data_2 = data.frame(time, data_2)
first = rnorm(45, mean = 10, sd = 1)
second = rnorm(45, mean = 20, sd = 1)
data_1 = c(first, second)
test_data_1 = data.frame(time, data_1)
data_fun = test_data_1 #edit here !!! (defines function for generating draws)
library("strucchange")
current_result = barA(bkpts_2$breakpoints, test_data_2[,1], test_data_2[,2], 50, 0.4)
bkpts_2 = breakpoints(test_data_2$data_2 ~ test_data_2$time, breaks = 5, h = 0.1)
current_result = barA(bkpts_2$breakpoints, test_data_2[,1], test_data_2[,2], 50, 0.4)
current_result = barA(bkpts_2$breakpoints, test_data_2[,1], test_data_2[,2], 50, 0.4, 0.1)
barA = function(k, time, data, iterations, make, percent){
library(MASS)
prob_mmm = c(make, make) #combining the two probabilties of make and murder that the user specifies
full_data = cbind(as.numeric(time), as.numeric(data)) #combing the time and data inputs from user
n = max(full_data[,1]) #finding max value
k_ends = c(min(full_data[,1]), na.omit(k), n) #adding in end points to k values
fitMetrics<-function(k_ends, full_data){
#create sum objects
sum_loglik = 0
#get and sum log likelihood for regressions of all intervals
if(length(k_ends) < 3 ){
model = lm(full_data[,2]~full_data[,1])
sum_loglik = logLik(model)[1]
}else{
for(i in 1:length(k_ends)) {
if(k_ends[i] == 2){
min = k_ends[i-1]
x_values = full_data[c(min:k_ends[i]),1] #getting the x values in the interval
y_values = full_data[c(min:k_ends[i]),2] #getting the y values in the interval
data = data.frame(x_values, y_values) #re-making this into a dataframe
model = lm(y_values~x_values) #running a lm on the selected interval
sum_loglik = sum_loglik + logLik(model)[1] #the logLik looks the log likelyhood (relates to both SSR and MLE)
}else if(k_ends[i] > 2){
min = k_ends[i-1]
x_values = full_data[c((min+1):k_ends[i]),1] #getting the x values in the interval
y_values = full_data[c((min+1):k_ends[i]),2] #getting the y values in the interval
data = data.frame(x_values, y_values) #re-making this into a dataframe
model = lm(y_values~x_values) #running a lm on the selected interval
sum_loglik = sum_loglik + logLik(model)[1] #the logLik looks the log likelyhood (relates to both SSR and MLE)
}
}
}
return(sum_loglik)
}
#random make function, this makes a random point
count = 0
barMake0<-function(k_ends){
count = count + 1 #this check to make sure we do not get stuck in an infinite loop
if(count < 10 ) {
rand_spot = sample(k_ends[1]:k_ends[length(k_ends)], 1) #selects a random spot
k_ends_final = sort(c(k_ends, rand_spot)) #adds the random spot and sorts it
d = diff(k_ends_final) #finds the difference between all the spots
if(min(d) < 3) { #this make sure an additional point is not to close to a point already in existance
barMake0(k_ends)
} else {
return(k_ends_final) #the old breakpoints + the new breakpoints
}
}else {
return(k_ends)
}
}
#this function kills one breakpoint randomly
barMurder0<-function(k_ends){
k = k_ends[c(-1,-length(k_ends))] #removes the end points
random_num = sample(1:length(k), 1) #selects a random breakpoint
k_ends_final = k_ends[-(random_num+1)] #removes that selected breakpoint
return(k_ends_final)
}
#jiggle jiggle jiggle
count = 0
barJiggle<-function(percent, k_ends, count){
count = count + 1
data_length = max(k_ends)
#determines how much the knot shoud jiggle
jiggle_range = ceiling(percent*data_length)
jiggle_neighborhood = c(1:jiggle_range)
jiggle_spot = sample(1:jiggle_neighborhood,1)
#"boolean" variable to make sure that we can jiggle
can_jiggle = "good" #default is good and we can jiggle
#determines randomly if knot is jiggling to left or right
direction = "right" #default direction is right
u = runif(1) #random number from 0-1 from uniform distribution
if(u < 0.5){
direction = "left"
jiggle_spot = (-1)*jiggle_spot
}
#determines randomly which knot is jiggling (code related to murders)
k = k_ends[c(-1, -length(k_ends))] #removes end points
rando_location = sample(1:length(k),1) #chooses random knot
rando_knot = k[rando_location]
#check if we can jiggle towards an endpoint
possible_knot = rando_knot+jiggle_spot
if(direction == "right"){
right_end = k_ends[length(k_ends)]
possible_diff = (abs(possible_knot - right_end) < 3)
if(possible_diff == TRUE){
can_jiggle = "bad"
}
}else{
left_end = k_ends[1]
possible_diff = (abs(possible_knot - left_end) < 3)
if(possible_diff == TRUE){
can_jiggle = "bad"
}
}
#check if new knot location already has a knot there
for(i in 1:length(k)){
possible_diff = (abs(possible_knot - k[i]) < 3)
if(rando_knot != k[i] & possible_diff == TRUE){
can_jiggle = "bad"
}
}
#check if we can jiggle, then jiggle!!!
if(can_jiggle == "bad" & count < 10){
barJiggle(percent, k_ends, count)
}else if(can_jiggle == "bad"){
return()
}else{
middle_set = k_ends[-(rando_location+1)]
final_set = sort(c(middle_set,possible_knot))
return(final_set)
}
}
#initializing matrices
ratio_data = data.frame()
all_k_new = matrix(NA, nrow=1, ncol=(n/3))
all_k_best = matrix(NA, nrow=1, ncol=(n/3))
bar_v = 0
bar_beta = 0
fit = 0
#matrix_of_fits = data.frame()
all_MSE = data.frame()
accept_count = 0
#setting up counters (these will tell us how many type it does a certain step and how many time it accept each step)
type = "0"
a.count = 0
s.count = 0
m.count = 0
add.accept.count = 0
sub.accept.count = 0
move.accept.count = 0
#setting up priors for drawing from betas
beta_lm = function(par) {#function to minimize to get MLE of betas
beta0 = par[1]  #current intercept
beta1 = par[2]  #current slope
sigma = sd(full_data[,2]) #standard deviation
#calculated likelihoods
lik = dnorm(full_data[,2], mean = full_data[,1] * beta1 + beta0, sd = sigma)
#convert likelihood to summary deviance score (minimizing deviance = maximizing likelihood)
log_lik = log(lik) #log likelihood of each data point
deviance = -2 * sum(log_lik) #calculate deviance
return(deviance)
}
beta_fits = optim(par = c(0, 0), fn = beta_lm, hessian = T) #get parameter estimates for betas
fisher = 0.5*beta_fits$hessian #if minimizing deviance, observed Fisher information is half of hessian
smiley = n * solve(fisher) #smiley face is total number of observations times the inverse of Fisher information
b_0 = matrix(beta_fits$par,2,1) #matrix of beta means for posterior draw
B_0 = smiley #variance-covariance matrix for posterior draw - IS THIS ILLEGAL?
#Metroplis Hastings
for(i in 1:iterations){
old_loglik = fitMetrics(k_ends, full_data) #calls fit matrix to have a function to start with
u_step = runif(1) #random number from 0 to 1 taken from a uniform distribution for selecting step
if(length(k_ends) < 3 | u_step < prob_mmm[1]){
type = "add"
a.count = a.count + 1
k_ends_new = barMake0(k_ends) #make
#setting up qs for ratio
q1 = make/(length(k_ends_new)-2)
full_set = c(k_ends, k_ends[1:length(k_ends-1)]+1, k_ends[1:length(k_ends-1)]+2, k_ends[2:length(k_ends)]-1, k_ends[2:length(k_ends)]-2) #all precluded observations
overlap = sum(table(full_set))-length(table(full_set)) #repeated preclusions
n_free = n - 5*(length(k_ends)-2) - 6 + overlap
q2 = make/n_free
} else if(u_step > prob_mmm[1] & u_step < sum(prob_mmm)){
type = "sub"
s.count = s.count + 1
k_ends_new = barMurder0(k_ends) #murder
#setting up qs for ratio
full_set = c(k_ends_new, k_ends_new[1:length(k_ends_new-1)]+1, k_ends_new[1:length(k_ends_new-1)]+2, k_ends_new[2:length(k_ends_new)]-1, k_ends_new[2:length(k_ends_new)]-2) #all precluded observations
overlap = sum(table(full_set))-length(table(full_set)) #repeated preclusions
n_free = n - 5*(length(k_ends)-2) - 6 + overlap
q1 = make/n_free
q2 = make/(length(k_ends)-2)
} else{
type = "move"
m.count = m.count + 1
count = 0 #for the jiggle function
k_ends_new = barJiggle(percent, k_ends, count) #jiggle
#fake qs because they cancel
q1 = 1
q2 = 1
}
new_loglik = fitMetrics(k_ends_new, full_data)
delta_bic = (-2*new_loglik + log(n)*(length(k_ends_new)-1)*(2+1)) - (-2*old_loglik + log(n)*(length(k_ends)-1)*(2+1))
ratio = (-delta_bic/2) + log(q1) - log(q2)
u_ratio = log(runif(1)) #random number from 0 to 1 taken from a uniform distribution and then log transformed
ratio_data_print = c(ratio, u_ratio, delta_bic, (-delta_bic/2), log(q1), log(q2))
if(abs(ratio) == Inf){ #safe guard against random models creating infinite ratios
k_ends = k_ends #old
} else if(ratio > u_ratio) {
k_ends = k_ends_new #new
accept_count = accept_count + 1
#looking at what type of step is done and accepted
if(type == "add") {
add.accept.count = add.accept.count + 1
} else if(type == "sub") {
sub.accept.count = sub.accept.count + 1
} else if(type == "move") {
move.accept.count = move.accept.count + 1
}
} else {
k_ends = k_ends #old
}
#condensing the data
k_ends_new_print = c(k_ends_new, rep(NA, (n/3)-length(k_ends_new)))
k_ends_best_print = c(k_ends, rep(NA, (n/3)-length(k_ends)))
ratio_data = rbind(ratio_data, ratio_data_print)
all_k_new = rbind(all_k_new, k_ends_new_print)
all_k_best = rbind(all_k_best, k_ends_best_print)
#setting up the posterior
##loop through the k_ends to find the intervals
fit = NULL
for(m in 2:length(k_ends)) {
len = length(k_ends)
if(m > 2){
min = k_ends[m-1]+1
}else{
min = k_ends[m-1]
}
x_values = full_data[c(min:k_ends[m]),1] #getting the x values in the interval
x_j = matrix(c( rep(1, each=length(x_values)), x_values), nrow= length(x_values), ncol= 2)
y_j = full_data[c(min:k_ends[m]),2] #getting the y values in the interval
sigma = sd(y_j)
#bar_v
v = solve( (1/sigma) * (t(x_j) %*% x_j )+ solve(B_0) )
#bar_beta
beta = v %*% ( (1/sigma) * (t(x_j) %*% y_j) + solve(B_0) %*% b_0 )
predicted_x = x_j %*% beta
fit = c(fit, predicted_x)
#drawing a random variable from a multivariate normal pdf
post_beta = mvrnorm(1, beta, v)
bar_v = c(bar_v, v)
bar_beta = c(bar_beta, beta)
if(m == len ) {
MSE = mean((full_data[,2]-fit)^2)
all_MSE = rbind(all_MSE, MSE)
}
}
}
#cleaning up the matrices
all_k_new = all_k_new[-1,colSums(is.na(all_k_new))<nrow(all_k_new)]
all_k_best = all_k_best[-1,colSums(is.na(all_k_best))<nrow(all_k_best)]
clean_max = max(all_k_new[1,], na.rm=TRUE)
all_k_new = ifelse(all_k_new == clean_max,NA,all_k_new)
all_k_best = ifelse(all_k_best == clean_max,NA,all_k_best)
all_k_new = data.frame(all_k_new[,c(-1,-ncol(all_k_new))], row.names=NULL)
all_k_best = data.frame(all_k_best[,c(-1,-ncol(all_k_best))], row.names=NULL)
colnames(ratio_data) = c("Ratio", "Random", "DeltaBIC", "LikeApprox", "LogQOldNew", "LogQNewOld")
colnames(all_MSE) = c("MSE")
final.propose = c(a.count, s.count, m.count)
final.accept = c(add.accept.count, sub.accept.count, move.accept.count)
final_list = list(accept_count / iterations, final.propose, final.accept, all_MSE, all_k_best)
names(final_list) = c("AcceptRate", "ProposedSteps","AcceptedSteps", "MSE", "Breakpoints")
return(final_list)
}
current_result = barA(bkpts_2$breakpoints, test_data_2[,1], test_data_2[,2], 50, 0.4, 0.1)
current_result
r =rmultinom(10, size = 12, prob = c(0.1,0.2,0.8))
r
r =rmultinom(10, size = 3, prob = c(0.1,0.2,0.8))
r
r =rmultinom(3, size = 1, prob = c(0.1,0.2,0.8))
r
r =rmultinom(1, size = 4, prob = c((1000/5320),(216/5370),(3375/5370), (729/5370)))
r
r =rmultinom(1, size = 1, prob = c((1000/5320),(216/5370),(3375/5370), (729/5370)))
r
r =rmultinom(1, size = 1, prob = c((1000/5320),(216/5370),(3375/5370), (729/5370)))
r
r =rmultinom(1, size = 1, prob = c((1000/5320),(216/5370),(3375/5370), (729/5370)))
r
r =rmultinom(1, size = 1000, prob = c((1000/5320),(216/5370),(3375/5370), (729/5370)))
r
v = c(10,6,15,9)
v^3
sum(v^3)
(v^3)/sum(v^3)
r =rmultinom(1, size = 1000, prob = (v^3)/sum(v^3))
r
r =rmultinom(1, size = 1, prob = (v^3)/sum(v^3))
r
k_ends_test = c(1,50,60)
barMake1<-function(k_ends){
d = diff(k_ends) #finding the distance between all those breakpoints
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
#locations = which(d == max(d) ) #finding the location(s) of the farthest distance
location = sample(d[locations], 1) #randomly select location in case of equal max distances
min = k_ends[location] #lower bound
max = k_ends[location + 1] #upper bound
new_bp = sample((min+3):(max-3), 1) #selecting a random number in the correct interval
k_ends_final = sort(c(k_ends, new_bp))
return(k_ends_final)
}
barMake1(k_ends_test)
barMake1<-function(k_ends){
d = diff(k_ends) #finding the distance between all those breakpoints
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
#locations = which(d == max(d) ) #finding the location(s) of the farthest distance
location = sample(d[location], 1) #randomly select location in case of equal max distances
min = k_ends[location] #lower bound
max = k_ends[location + 1] #upper bound
new_bp = sample((min+3):(max-3), 1) #selecting a random number in the correct interval
k_ends_final = sort(c(k_ends, new_bp))
return(k_ends_final)
}
barMake1(k_ends_test)
k_ends = c(1.50,60)
d = diff(k_ends) #finding the distance between all those breakpoints
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
location
d[location]
d
d = diff(k_ends) #finding the distance between all those breakpoints
d
d = diff(k_ends) #finding the distance between all those breakpoints
k_ends_test = c(1,50,60)
k_ends = c(1,30,50,60)
d = diff(k_ends) #finding the distance between all those breakpoints
d
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
locations = sample(d[location], 1) #randomly select location in case of equal max distances
locations
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
min = k_ends[location] #lower bound
max = k_ends[location + 1] #upper bound
new_bp = sample((min+3):(max-3), 1) #selecting a random number in the correct interval
min
max
d = diff(k_ends) #finding the distance between all those breakpoints
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
min = k_ends[location] #lower bound
max = k_ends[location + 1] #upper bound
min
max
max = k_ends[(location + 1)] #upper bound
max
location
location=0
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
location
which.max(location)
min = k_ends[which.max(location)] #lower bound
min
max = k_ends[(which.max(location) + 1)] #upper bound
max
new_bp = sample((min+3):(max-3), 1) #selecting a random number in the correct interval
new_bp
k_ends_final = sort(c(k_ends, new_bp))
return(k_ends_final)
k_ends_test = c(1,50,60)
barMake1<-function(k_ends){
d = diff(k_ends) #finding the distance between all those breakpoints
location = rmultinom(1, size = 1, prob = (d^3)/sum(d^3))
#locations = which(d == max(d) ) #finding the location(s) of the farthest distance
#locations = sample(d[location], 1) #randomly select location in case of equal max distances
min = k_ends[which.max(location)] #lower bound
max = k_ends[(which.max(location) + 1)] #upper bound
new_bp = sample((min+3):(max-3), 1) #selecting a random number in the correct interval
k_ends_final = sort(c(k_ends, new_bp))
return(k_ends_final)
}
barMake1(k_ends_test)
k_ends_test = c(1, 20, 40, 60, 80)
k_ends = c(1, 20, 40, 60, 80)
all_intv = diff(k_ends) #finds all of the intervals
all_intv
sum_intv = diff(cumsum(all_intv)) #finds the sums of the adjacent intervals
k_ends = c(7,17,30,6)
all_intv = diff(k_ends) #finds all of the intervals
all_intv
k_ends = c(7,24,54,60)
all_intv = diff(k_ends) #finds all of the intervals
all_intv
k_ends = c(1,7,24,54,60)
all_intv = diff(k_ends) #finds all of the intervals
all_intv
k_ends = c(1,8,25,55,60)
all_intv = diff(k_ends) #finds all of the intervals
all_intv
sum_intv = diff(cumsum(all_intv)) #finds the sums of the adjacent intervals
sum_intv
small_intv_loc = which(sum_intv == min(sum_intv)) #stores indexes of smallest sum_intv
small_intv_loc
k_ends = c(1,8,25,55,60)
all_intv = diff(k_ends) #finds all of the intervals
all_intv
sum_intv = diff(cumsum(all_intv)) #finds the sums of the adjacent intervals
sum_intv
cumsum(all_intv)
diff(cumsum(all_intv))
all_intv
a = all_intv[-1]
a
all_intv + a
k_ends = c(1,8,25,55,60)
all_intv = diff(k_ends) #finds all of the intervals
all_intv
in = all_intv[-1]
b = all_intv[-1]
b
b = c(b,0)
b
all_intv + b
b
k_ends = c(1,8,25,55,60)
all_intv = diff(k_ends) #finds all of the intervals
a = all_intv[-1]
a
b = all_intv[length(all_intv)]
b
b = all_intv[-length(all_intv)]
b
a + b
a
b
a +b
c = a+ b
c
1/c
sum(1/c)
(1/c)/sum(1/c)
k_ends = c(1,8,25,55,60)
all_intv = diff(k_ends) #finds all of the intervals
intv_1 = all_intv[-1]
intv_2 = all_intv(-length(all_intv))
sum_intv = intv_1 + intv_2 #finds the sums of the adjacent intervals
all_intv = diff(k_ends) #finds all of the intervals
intv_1 = all_intv[-1]
intv_2 = all_intv(-length(all_intv))
intv_2 = all_intv[-length(all_intv)]
sum_intv = intv_1 + intv_2 #finds the sums of the adjacent intervals
sum_intv
location = rmultinom(1, size = 1, prob = (1/sum_intv)/sum(1/sum_intv))
location
max(location)
which.max(location)
k_ends_final = k_ends[-(which.max(location)+1)]
k_ends_final
k_ends = c(1,8,60)
all_intv = diff(k_ends) #finds all of the intervals
intv_1 = all_intv[-1]
intv_2 = all_intv[-length(all_intv)]
sum_intv = intv_1 + intv_2 #finds the sums of the adjacent intervals
location = rmultinom(1, size = 1, prob = (1/sum_intv)/sum(1/sum_intv))
min_intv_loc = 0 #sets the minimum sum_intv index to 0
k_ends_final = k_ends[-(which.max(location)+1)]
k_ends_final
setwd("~/REU2018")
setwd("~/REU2018/Move_simulation_data")
test = readRDS("bar0_data0a.RData")
summary(test)
test$MSE
plot(test$MSE)
plot(test$MSE)
graphics.off
graphics.off()
plot(test$MSE[,1])
plot(c(test$MSE[,1],test$MSE[,2])
)
plot(c(test$MSE[,1],test$MSE[,2]))
plot(c(test$MSE[,1],test$MSE[,2]),test$MSE[,3]),test$MSE[,4]),test$MSE[,5]))
plot(c(test$MSE[,1],test$MSE[,2],test$MSE[,3],test$MSE[,4],test$MSE[,5]))
graphics.off()
rm(list=ls())
cat("\014")
